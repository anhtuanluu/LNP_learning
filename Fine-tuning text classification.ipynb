{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fine-tuning with custom.ipynb","provenance":[],"authorship_tag":"ABX9TyO4IgdAjDLcbocL86W8DoAL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n9agV94CfCKM","executionInfo":{"status":"ok","timestamp":1606293672300,"user_tz":-420,"elapsed":739,"user":{"displayName":"Anh Tu·∫•n L∆∞u Xu√¢n","photoUrl":"","userId":"09929006387311900042"}},"outputId":"03f1e677-f8b0-42cf-9339-2a0f96bf112d"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Wed Nov 25 08:41:11 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   52C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MdcbBPKhe2h4","executionInfo":{"status":"ok","timestamp":1606293684956,"user_tz":-420,"elapsed":13383,"user":{"displayName":"Anh Tu·∫•n L∆∞u Xu√¢n","photoUrl":"","userId":"09929006387311900042"}},"outputId":"01380ea2-aae3-4a5c-8d76-e0e2b8e081fa"},"source":["!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-11-25 08:41:12--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n","Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 84125825 (80M) [application/x-gzip]\n","Saving to: ‚ÄòaclImdb_v1.tar.gz.4‚Äô\n","\n","aclImdb_v1.tar.gz.4 100%[===================>]  80.23M  24.4MB/s    in 3.5s    \n","\n","2020-11-25 08:41:16 (22.9 MB/s) - ‚ÄòaclImdb_v1.tar.gz.4‚Äô saved [84125825/84125825]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KouLIkPSflRO","executionInfo":{"status":"ok","timestamp":1606293687378,"user_tz":-420,"elapsed":15798,"user":{"displayName":"Anh Tu·∫•n L∆∞u Xu√¢n","photoUrl":"","userId":"09929006387311900042"}},"outputId":"dfdff7e9-f04b-4191-bbcf-d0f7b01f2a10"},"source":["!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Yh4kRW94fOJC","executionInfo":{"status":"ok","timestamp":1606293688726,"user_tz":-420,"elapsed":17139,"user":{"displayName":"Anh Tu·∫•n L∆∞u Xu√¢n","photoUrl":"","userId":"09929006387311900042"}}},"source":["from pathlib import Path\n","\n","def read_imdb_split(split_dir):\n","    split_dir = Path(split_dir)\n","    texts = []\n","    labels = []\n","    for label_dir in [\"pos\", \"neg\"]:\n","        for text_file in (split_dir/label_dir).iterdir():\n","            texts.append(text_file.read_text())\n","            labels.append(0 if label_dir is \"neg\" else 1)\n","\n","    return texts, labels\n","\n","train_texts, train_labels = read_imdb_split('aclImdb/train')\n","test_texts, test_labels = read_imdb_split('aclImdb/test')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"yOvkfnkCfVWt","executionInfo":{"status":"ok","timestamp":1606293688727,"user_tz":-420,"elapsed":17135,"user":{"displayName":"Anh Tu·∫•n L∆∞u Xu√¢n","photoUrl":"","userId":"09929006387311900042"}},"outputId":"b7b7fcf3-0f47-4235-cc9a-59a2be9eaf21"},"source":["train_texts[0]"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'I rank this the best of the Zorro chapterplays.The exciting musical score adds punch to an exciting screen play.There is an excellent supporting cast and mystery villain that will keep you guessing until the final chapter.Reed Hadley does a fine job as Don Diego and his alter ego Zorro.Last,but certainly not least,is the great directing team of Whitney and English.'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"eTurlqNRfe4b","executionInfo":{"status":"ok","timestamp":1606293689651,"user_tz":-420,"elapsed":18052,"user":{"displayName":"Anh Tu·∫•n L∆∞u Xu√¢n","photoUrl":"","userId":"09929006387311900042"}}},"source":["from sklearn.model_selection import train_test_split\n","train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"62-wFczSfg-s","executionInfo":{"status":"ok","timestamp":1606293699313,"user_tz":-420,"elapsed":27708,"user":{"displayName":"Anh Tu·∫•n L∆∞u Xu√¢n","photoUrl":"","userId":"09929006387311900042"}}},"source":["from transformers import DistilBertTokenizerFast\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZPCWtv5dfwtP","executionInfo":{"status":"ok","timestamp":1606293730159,"user_tz":-420,"elapsed":58548,"user":{"displayName":"Anh Tu·∫•n L∆∞u Xu√¢n","photoUrl":"","userId":"09929006387311900042"}}},"source":["train_encodings = tokenizer(train_texts,max_length=512, truncation=True, padding=True)\n","val_encodings = tokenizer(val_texts,max_length=512, truncation=True, padding=True)\n","test_encodings = tokenizer(test_texts,max_length=512, truncation=True, padding=True)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"oSINc3x-fzdy","executionInfo":{"status":"ok","timestamp":1606293730160,"user_tz":-420,"elapsed":58544,"user":{"displayName":"Anh Tu·∫•n L∆∞u Xu√¢n","photoUrl":"","userId":"09929006387311900042"}}},"source":["import torch\n","\n","class IMDbDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = IMDbDataset(train_encodings, train_labels)\n","val_dataset = IMDbDataset(val_encodings, val_labels)\n","test_dataset = IMDbDataset(test_encodings, test_labels)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTTsMKz7gDfx","executionInfo":{"status":"ok","timestamp":1606293730161,"user_tz":-420,"elapsed":58539,"user":{"displayName":"Anh Tu·∫•n L∆∞u Xu√¢n","photoUrl":"","userId":"09929006387311900042"}},"outputId":"783aeea5-19f9-41d7-bfc7-f30a9ef2f7ec"},"source":["train_dataset[0][\"input_ids\"].shape, train_dataset[0][\"labels\"]"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([512]), tensor(0))"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335},"id":"kro-O3jkhBCD","outputId":"a6c1e84e-ea7a-447f-f59f-6a64f14005c5"},"source":["from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',          # output directory\n","    num_train_epochs=3,              # total number of training epochs\n","    per_device_train_batch_size=16,  # batch size per device during training\n","    per_device_eval_batch_size=64,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir='./logs',            # directory for storing logs\n","    logging_steps=10,\n",")\n","\n","model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n","\n","trainer = Trainer(\n","    model=model,                         # the instantiated ü§ó Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=val_dataset             # evaluation dataset\n",")\n","\n","trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='59' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  59/3750 00:43 < 46:36, 1.32 it/s, Epoch 0.05/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.687507</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.696761</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.696103</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.689289</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.683462</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]}]}
